{"cells":[{"cell_type":"markdown","metadata":{"id":"mFWYOBah_6Rl"},"source":["# Financial Market Analytics"]},{"cell_type":"markdown","metadata":{"id":"lNIgbXpKAXMn"},"source":["\n","> Google Cloud,\n","\n","> Yahoo Finance,\n","\n",">  S&P 500 Indices,\n","\n","> Open Source, Business Analytics\n","\n","> Financial Analytics and Entrepreneurial drive.\n","\n","> Note: Financial markets are subject to highly volatile and non-stationary. AI and Data exploration purpose.\n","\n","\n","\n"]},{"cell_type":"markdown","source":["# Healthcare Markets - Financial Analysis"],"metadata":{"id":"vR-Reynx5dwP"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":790},"id":"Sq23wGezCOlN","outputId":"dc50bd12-f2d5-49b4-febd-94b3df673a5f","executionInfo":{"status":"error","timestamp":1730209125997,"user_tz":-60,"elapsed":41383,"user":{"displayName":"Vivekanand R","userId":"12007457921190987055"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pandas_ta\n","  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/115.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m112.6/115.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ta\n","  Downloading ta-0.11.0.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pandas_ta) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ta) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.16.0)\n","Building wheels for collected packages: pandas_ta, ta\n","  Building wheel for pandas_ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pandas_ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218909 sha256=65dd47087c5deaad1105af8b9cf5d88f50be925c58fd25c30fb6a7fd81da0dff\n","  Stored in directory: /root/.cache/pip/wheels/69/00/ac/f7fa862c34b0e2ef320175100c233377b4c558944f12474cf0\n","  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=6fc81d45244edd345f5296a83878afacc2faca37786a0bf742402f691dd530a4\n","  Stored in directory: /root/.cache/pip/wheels/5f/67/4f/8a9f252836e053e532c6587a3230bc72a4deb16b03a829610b\n","Successfully built pandas_ta ta\n","Installing collected packages: ta, pandas_ta\n","Successfully installed pandas_ta-0.3.14b0 ta-0.11.0\n","Mounted at /content/drive\n","Number of tickers: 1000\n","Processing 1/1000: AAPL...\n"]},{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed\n"]},{"output_type":"error","ename":"ValueError","evalue":"Data must be 1-dimensional, got ndarray of shape (252, 1) instead","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-ccbcff210340>\u001b[0m in \u001b[0;36m<cell line: 206>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;31m# Execute the main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-ccbcff210340>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing {index + 1}/{len(tickers)}: {ticker}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mresult_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_indicators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mall_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-ccbcff210340>\u001b[0m in \u001b[0;36mcalculate_indicators\u001b[0;34m(ticker)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# Get today's and yesterday's score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mscore_today\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_today\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0mscore_yesterday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_yesterday\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-ccbcff210340>\u001b[0m in \u001b[0;36mget_score\u001b[0;34m(data, day_offset)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# MACD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mmacd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMACD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mmacd_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmacd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmacd_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mday_offset\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MACD'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmacd_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmacd_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ta/trend.py\u001b[0m in \u001b[0;36mmacd_diff\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \"\"\"\n\u001b[1;32m    152\u001b[0m         \u001b[0mmacd_diff_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_macd_diff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         return pd.Series(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0mmacd_diff_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"MACD_diff_{self._window_fast}_{self._window_slow}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.data_manager\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         return sanitize_array(\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    657\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m     \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_ndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36m_sanitize_ndim\u001b[0;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    719\u001b[0m                 \u001b[0;34mf\"Data must be 1-dimensional, got ndarray of shape {data.shape} instead\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (252, 1) instead"]}],"source":["!pip install pandas_ta ta\n","import yfinance as yf\n","import pandas as pd\n","import ta\n","import numpy as np\n","from google.colab import drive\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\", category=FutureWarning, module='ta.trend')\n","\n","# Mount Google Drive to access files\n","drive.mount('/content/drive', force_remount=True)\n","\n","# File paths\n","drive_path = '/content/drive/My Drive/Colab Notebooks'\n","input_file_path = f'{drive_path}/Stock_List.xlsx'\n","output_file_path = f'{drive_path}/BB_Results_v5A_US1000_12cons_2RSI_Backtesting_v1.xlsx'\n","sheet_name = 'US_1000'\n","\n","# Function to calculate indicators for a given ticker\n","def calculate_indicators(ticker):\n","    data = yf.download(ticker, period='1y', interval='1d')\n","    if data.empty or len(data) < 200:  # Ensure there is enough data for long-term indicators\n","        print(f\"Insufficient data for {ticker}\")\n","        return pd.DataFrame()  # Skip this stock\n","\n","    # The rest of your indicator calculations\n","\n","\n","    # Calculate scores for today and yesterday\n","    def get_score(data, day_offset=0):\n","        score = 0\n","        results = {}\n","\n","        # MACD\n","        macd = ta.trend.MACD(data['Close'])\n","        macd_score = int(macd.macd_diff().iloc[-1 - day_offset] > 0)\n","        results['MACD'] = macd_score\n","        score += macd_score\n","\n","        # RSI with additional condition (RSI yesterday > RSI day before yesterday)\n","        rsi = ta.momentum.RSIIndicator(data['Close']).rsi()\n","        rsi_score = int(30 < rsi.iloc[-1 - day_offset] < 60 and rsi.iloc[-1 - day_offset] > rsi.iloc[-2 - day_offset])\n","        results['RSI'] = rsi_score\n","        score += rsi_score\n","\n","        # Golden Cross\n","        sma50 = ta.trend.SMAIndicator(data['Close'], 50).sma_indicator()\n","        sma200 = ta.trend.SMAIndicator(data['Close'], 200).sma_indicator()\n","        ma_score = int(sma50.iloc[-1 - day_offset] > sma200.iloc[-1 - day_offset])\n","        results['Golden Cross'] = ma_score\n","        score += ma_score\n","\n","        # # Bollinger Bands\n","        # bb = ta.volatility.BollingerBands(data['Close'])\n","        # bb_score = int(data['Close'].iloc[-1 - day_offset] > bb.bollinger_hband().iloc[-1 - day_offset])\n","        # results['Bollinger Bands'] = bb_score\n","        # score += bb_score\n","\n","        # Bollinger Bands, # Using the middle band (20-day SMA) instead of the upper band\n","\n","        bb = ta.volatility.BollingerBands(data['Close'])\n","        middle_band = bb.bollinger_mavg()  # This represents the 20-day SMA\n","             # Scoring logic: 1 point if the price is above the middle Bollinger Band\n","        bb_score = int(data['Close'].iloc[-1 - day_offset] > middle_band.iloc[-1 - day_offset])\n","            # Add this to the results and overall score\n","        results['Bollinger Bands'] = bb_score\n","        score += bb_score\n","\n","        # Volume\n","        avg_vol = data['Volume'].rolling(window=20).mean()\n","        vol_score = int(data['Volume'].iloc[-1 - day_offset] > avg_vol.iloc[-1 - day_offset])\n","        results['Volume'] = vol_score\n","        score += vol_score\n","\n","        # OBV\n","        obv = ta.volume.OnBalanceVolumeIndicator(data['Close'], data['Volume']).on_balance_volume()\n","        obv_score = int(obv.diff().iloc[-1 - day_offset] > 0)\n","        results['OBV'] = obv_score\n","        score += obv_score\n","\n","        # Accumulation/Distribution Line\n","        ad = ta.volume.AccDistIndexIndicator(data['High'], data['Low'], data['Close'], data['Volume']).acc_dist_index()\n","        ad_score = int(ad.diff().iloc[-1 - day_offset] > 0)\n","        results['Acc/Dist Line'] = ad_score\n","        score += ad_score\n","\n","        # Chaikin Money Flow\n","        cmf = ta.volume.ChaikinMoneyFlowIndicator(data['High'], data['Low'], data['Close'], data['Volume']).chaikin_money_flow()\n","        cmf_score = int(cmf.iloc[-1 - day_offset] > 0)\n","        results['CMF'] = cmf_score\n","        score += cmf_score\n","\n","        # Parabolic SAR\n","        psar = ta.trend.PSARIndicator(data['High'], data['Low'], data['Close']).psar()\n","        psar_score = int(data['Close'].iloc[-1 - day_offset] > psar.iloc[-1 - day_offset])\n","        results['Parabolic SAR'] = psar_score\n","        score += psar_score\n","\n","        # Stochastic Oscillator\n","        stoch = ta.momentum.StochasticOscillator(data['High'], data['Low'], data['Close'])\n","        stoch_score = int(stoch.stoch_signal().iloc[-1 - day_offset] > stoch.stoch().iloc[-1 - day_offset] and stoch.stoch().iloc[-1 - day_offset] < 20)\n","        results['Stochastic'] = stoch_score\n","        score += stoch_score\n","\n","        # Fibonacci Retracement\n","        max_price = data['Close'].max()\n","        min_price = data['Close'].min()\n","        fib_50 = min_price + (max_price - min_price) * 0.5\n","        fib_score = int(data['Close'].iloc[-1 - day_offset] > fib_50)\n","        results['Fib Retracement'] = fib_score\n","        score += fib_score\n","\n","        # ADX\n","        adx = ta.trend.ADXIndicator(data['High'], data['Low'], data['Close']).adx()\n","        plus_di = ta.trend.ADXIndicator(data['High'], data['Low'], data['Close']).adx_pos()\n","        minus_di = ta.trend.ADXIndicator(data['High'], data['Low'], data['Close']).adx_neg()\n","        adx_score = int(adx.iloc[-1 - day_offset] > 20 and plus_di.iloc[-1 - day_offset] > minus_di.iloc[-1 - day_offset])\n","        results['ADX'] = adx_score\n","        score += adx_score\n","\n","        # Price Action & Trendlines\n","        pa_score = int(data['Close'].iloc[-1 - day_offset] > data['Close'].rolling(window=20).max().iloc[-2 - day_offset])\n","        results['Price Action'] = pa_score\n","        score += pa_score\n","\n","        # Candlestick Patterns (Hammer)\n","        def hammer_pattern(data):\n","            open, close, low = data['Open'], data['Close'], data['Low']\n","            return ((close > open) and (open - low) > 2 * (close - open))\n","\n","        hammer_score = int(hammer_pattern(data.iloc[-1 - day_offset]))\n","        results['Candlestick'] = hammer_score\n","        score += hammer_score\n","\n","        # Ichimoku Cloud\n","        ichimoku = ta.trend.IchimokuIndicator(data['High'], data['Low'], window1=9, window2=26, window3=52)\n","        ich_score = int(data['Close'].iloc[-1 - day_offset] > ichimoku.ichimoku_a().iloc[-1 - day_offset] and data['Close'].iloc[-1 - day_offset] > ichimoku.ichimoku_b().iloc[-1 - day_offset])\n","        results['Ichimoku'] = ich_score\n","        score += ich_score\n","\n","        return score, results\n","\n","    # Get today's and yesterday's score\n","    score_today, results_today = get_score(data)\n","    score_yesterday, results_yesterday = get_score(data, day_offset=1)\n","\n","    # Create result DataFrame\n","    result_df = pd.DataFrame([results_today])\n","    result_df['Stock'] = ticker\n","    result_df['Bullish Score Today'] = score_today\n","    result_df['Bullish Score Yesterday'] = score_yesterday\n","    result_df['Score Difference'] = score_today - score_yesterday\n","\n","    # Add Today Change % and Yesterday Change %\n","    result_df['Today Change %'] = (data['Close'].iloc[-1] - data['Close'].iloc[-2]) / data['Close'].iloc[-2] * 100\n","    result_df['Yesterday Change %'] = (data['Close'].iloc[-2] - data['Close'].iloc[-3]) / data['Close'].iloc[-3] * 100\n","\n","    # Reorder columns for better presentation\n","    columns_order = ['Stock'] + list(results_today.keys()) + ['Bullish Score Today', 'Bullish Score Yesterday', 'Score Difference', 'Today Change %', 'Yesterday Change %']\n","    result_df = result_df[columns_order]\n","\n","    return result_df\n","\n","# Main function to process multiple tickers\n","def main():\n","    # Read the Excel sheet with tickers\n","    global final_df2, final_df, result_df, all_results\n","\n","    ticker_data = pd.read_excel(input_file_path, sheet_name=sheet_name)\n","    tickers = ticker_data['Ticker'].tolist()\n","    number_of_tickers = len(tickers)\n","    print(\"Number of tickers:\", number_of_tickers)\n","\n","    # Initialize a list to store results for each ticker\n","    all_results = []\n","\n","    # Calculate indicators for each ticker and collect results\n","    for index, ticker in enumerate(tickers):\n","        print(f\"Processing {index + 1}/{len(tickers)}: {ticker}...\")\n","        result_df = calculate_indicators(ticker)\n","        if not result_df.empty:\n","            all_results.append(result_df)\n","\n","\n","    # Combine all results into a single DataFrame\n","    if all_results:\n","        final_df = pd.concat(all_results, ignore_index=True)\n","        final_df = final_df[(final_df['Score Difference'] > 0) & (final_df['Bullish Score Today'] > 10) & (final_df['RSI'] == 1) & (final_df['MACD'] == 1) ]\n","        final_df = final_df.sort_values(by='Score Difference', ascending=False)\n","        final_df2 = final_df\n","        display(final_df2)\n","\n","        # Save the results to the Excel file\n","        try:\n","            existing_df = pd.read_excel(output_file_path)\n","            final_df = pd.concat([existing_df, final_df], ignore_index=True)\n","        except FileNotFoundError:\n","            print(f\"{output_file_path} not found. A new file will be created.\")\n","\n","        final_df.to_excel(output_file_path, index=False)\n","    else:\n","        print(\"No valid signals detected for any stock.\")\n","\n","# Execute the main function\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"markdown","metadata":{"id":"k3C9i0nWAyhI"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RfUibeia8SgE"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MEO3Td8gCO6J"},"outputs":[],"source":["!pip install pandas_ta ta\n"]},{"cell_type":"markdown","metadata":{"id":"M8DELKB9BvTs"},"source":["# US Market: Few Public Traded Companies and its technical score as on Oct 29th 2024:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5lMlVKKtdvhY"},"outputs":[],"source":["# Import necessary libraries\n","import yfinance as yf\n","import pandas as pd\n","import ta\n","import numpy as np\n","from google.colab import drive\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\", category=FutureWarning, module='ta.trend')\n","\n","# Mount Google Drive to save files\n","drive.mount('/content/drive', force_remount=True)\n","\n","# File paths\n","drive_path = '/content/drive/My Drive/Colab Notebooks'\n","output_file_path = f'{drive_path}/BB_Results_v5A_US1000_12cons_2RSI_Backtesting_v1.xlsx'\n","\n","# Function to calculate indicators for a given ticker\n","def calculate_indicators(ticker):\n","    data = yf.download(ticker, period='1y', interval='1d')\n","    if data.empty or len(data) < 200:  # Ensure there is enough data for long-term indicators\n","        print(f\"Insufficient data for {ticker}\")\n","        return pd.DataFrame()  # Skip this stock\n","\n","    # Calculate scores for today and yesterday\n","    def get_score(data, day_offset=0):\n","        score = 0\n","        results = {}\n","\n","        # MACD\n","        macd = ta.trend.MACD(data['Close'])\n","        macd_score = int(macd.macd_diff().iloc[-1 - day_offset] > 0)\n","        results['MACD'] = macd_score\n","        score += macd_score\n","\n","        # RSI with additional condition (RSI yesterday > RSI day before yesterday)\n","        rsi = ta.momentum.RSIIndicator(data['Close']).rsi()\n","        rsi_score = int(30 < rsi.iloc[-1 - day_offset] < 60 and rsi.iloc[-1 - day_offset] > rsi.iloc[-2 - day_offset])\n","        results['RSI'] = rsi_score\n","        score += rsi_score\n","\n","        # Golden Cross\n","        sma50 = ta.trend.SMAIndicator(data['Close'], 50).sma_indicator()\n","        sma200 = ta.trend.SMAIndicator(data['Close'], 200).sma_indicator()\n","        ma_score = int(sma50.iloc[-1 - day_offset] > sma200.iloc[-1 - day_offset])\n","        results['Golden Cross'] = ma_score\n","        score += ma_score\n","\n","        # Bollinger Bands\n","        bb = ta.volatility.BollingerBands(data['Close'])\n","        middle_band = bb.bollinger_mavg()  # This represents the 20-day SMA\n","        bb_score = int(data['Close'].iloc[-1 - day_offset] > middle_band.iloc[-1 - day_offset])\n","        results['Bollinger Bands'] = bb_score\n","        score += bb_score\n","\n","        # Volume\n","        avg_vol = data['Volume'].rolling(window=20).mean()\n","        vol_score = int(data['Volume'].iloc[-1 - day_offset] > avg_vol.iloc[-1 - day_offset])\n","        results['Volume'] = vol_score\n","        score += vol_score\n","\n","        # OBV\n","        obv = ta.volume.OnBalanceVolumeIndicator(data['Close'], data['Volume']).on_balance_volume()\n","        obv_score = int(obv.diff().iloc[-1 - day_offset] > 0)\n","        results['OBV'] = obv_score\n","        score += obv_score\n","\n","        # Accumulation/Distribution Line\n","        ad = ta.volume.AccDistIndexIndicator(data['High'], data['Low'], data['Close'], data['Volume']).acc_dist_index()\n","        ad_score = int(ad.diff().iloc[-1 - day_offset] > 0)\n","        results['Acc/Dist Line'] = ad_score\n","        score += ad_score\n","\n","        # Chaikin Money Flow\n","        cmf = ta.volume.ChaikinMoneyFlowIndicator(data['High'], data['Low'], data['Close'], data['Volume']).chaikin_money_flow()\n","        cmf_score = int(cmf.iloc[-1 - day_offset] > 0)\n","        results['CMF'] = cmf_score\n","        score += cmf_score\n","\n","        # Parabolic SAR\n","        psar = ta.trend.PSARIndicator(data['High'], data['Low'], data['Close']).psar()\n","        psar_score = int(data['Close'].iloc[-1 - day_offset] > psar.iloc[-1 - day_offset])\n","        results['Parabolic SAR'] = psar_score\n","        score += psar_score\n","\n","        # Stochastic Oscillator\n","        stoch = ta.momentum.StochasticOscillator(data['High'], data['Low'], data['Close'])\n","        stoch_score = int(stoch.stoch_signal().iloc[-1 - day_offset] > stoch.stoch().iloc[-1 - day_offset] and stoch.stoch().iloc[-1 - day_offset] < 20)\n","        results['Stochastic'] = stoch_score\n","        score += stoch_score\n","\n","        # Fibonacci Retracement\n","        max_price = data['Close'].max()\n","        min_price = data['Close'].min()\n","        fib_50 = min_price + (max_price - min_price) * 0.5\n","        fib_score = int(data['Close'].iloc[-1 - day_offset] > fib_50)\n","        results['Fib Retracement'] = fib_score\n","        score += fib_score\n","\n","        # ADX\n","        adx = ta.trend.ADXIndicator(data['High'], data['Low'], data['Close']).adx()\n","        plus_di = ta.trend.ADXIndicator(data['High'], data['Low'], data['Close']).adx_pos()\n","        minus_di = ta.trend.ADXIndicator(data['High'], data['Low'], data['Close']).adx_neg()\n","        adx_score = int(adx.iloc[-1 - day_offset] > 20 and plus_di.iloc[-1 - day_offset] > minus_di.iloc[-1 - day_offset])\n","        results['ADX'] = adx_score\n","        score += adx_score\n","\n","        # Price Action & Trendlines\n","        pa_score = int(data['Close'].iloc[-1 - day_offset] > data['Close'].rolling(window=20).max().iloc[-2 - day_offset])\n","        results['Price Action'] = pa_score\n","        score += pa_score\n","\n","        # Candlestick Patterns (Hammer)\n","        def hammer_pattern(data):\n","            open, close, low = data['Open'], data['Close'], data['Low']\n","            return ((close > open) and (open - low) > 2 * (close - open))\n","\n","        hammer_score = int(hammer_pattern(data.iloc[-1 - day_offset]))\n","        results['Candlestick'] = hammer_score\n","        score += hammer_score\n","\n","        # Ichimoku Cloud\n","        ichimoku = ta.trend.IchimokuIndicator(data['High'], data['Low'], window1=9, window2=26, window3=52)\n","        ich_score = int(data['Close'].iloc[-1 - day_offset] > ichimoku.ichimoku_a().iloc[-1 - day_offset] and data['Close'].iloc[-1 - day_offset] > ichimoku.ichimoku_b().iloc[-1 - day_offset])\n","        results['Ichimoku'] = ich_score\n","        score += ich_score\n","\n","        return score, results\n","\n","    # Get today's and yesterday's score\n","    score_today, results_today = get_score(data)\n","    score_yesterday, results_yesterday = get_score(data, day_offset=1)\n","\n","    # Create result DataFrame\n","    result_df = pd.DataFrame([results_today])\n","    result_df['Stock'] = ticker\n","    result_df['Bullish Score Today'] = score_today\n","    result_df['Bullish Score Yesterday'] = score_yesterday\n","    result_df['Score Difference'] = score_today - score_yesterday\n","\n","    # Add Today Change % and Yesterday Change %\n","    result_df['Today Change %'] = (data['Close'].iloc[-1] - data['Close'].iloc[-2]) / data['Close'].iloc[-2] * 100\n","    result_df['Yesterday Change %'] = (data['Close'].iloc[-2] - data['Close'].iloc[-3]) / data['Close'].iloc[-3] * 100\n","\n","    # Reorder columns for better presentation\n","    columns_order = ['Stock'] + list(results_today.keys()) + ['Bullish Score Today', 'Bullish Score Yesterday', 'Score Difference', 'Today Change %', 'Yesterday Change %']\n","    result_df = result_df[columns_order]\n","\n","    return result_df\n","\n","# Main function to process specific tickers\n","def main():\n","    # Hardcoded list of tickers you want to analyze\n","    tickers = ['AAPL', 'GOOGL', 'NSRGY', 'GEHC', 'FRSH', 'RHHBY', 'NVS', 'JNJ', 'AMZN', 'MSFT', 'NVDA', 'TSLA']\n","    number_of_tickers = len(tickers)\n","    print(\"Number of tickers:\", number_of_tickers)\n","\n","    # Initialize a list to store results for each ticker\n","    all_results = []\n","\n","    # Calculate indicators for each ticker and collect results\n","    for index, ticker in enumerate(tickers):\n","        print(f\"Processing {index + 1}/{len(tickers)}: {ticker}...\")\n","        result_df = calculate_indicators(ticker)\n","        if not result_df.empty:\n","            all_results.append(result_df)\n","\n","    # Combine all results into a single DataFrame\n","    if all_results:\n","        final_df = pd.concat(all_results, ignore_index=True)\n","        #final_df = final_df[(final_df['Score Difference'] > 0) & (final_df['Bullish Score Today'] > 10) & (final_df['RSI'] == 1) & (final_df['MACD'] == 1) ]\n","        final_df = final_df.sort_values(by='Score Difference', ascending=False)\n","        final_df2 = final_df\n","        display(final_df2)\n","\n","        # Save the results to the Excel file\n","        try:\n","            existing_df = pd.read_excel(output_file_path)\n","            final_df = pd.concat([existing_df, final_df], ignore_index=True)\n","        except FileNotFoundError:\n","            print(f\"{output_file_path} not found. A new file will be created.\")\n","\n","        final_df.to_excel(output_file_path, index=False)\n","    else:\n","        print(\"No valid signals detected for any stock.\")\n","\n","# Execute the main function\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"markdown","metadata":{"id":"5yVvNLQFEiLU"},"source":["# Swiss Market: Top 30 Companies"]},{"cell_type":"code","source":["print(\"• Nestlé (NESN.SW) - Market Cap: $340 billion USD, Revenue: $95 billion USD, Employees: 270,000, PE Ratio: 25, Key Products: Food & Beverages\\n\")\n","print(\"• Roche Holding (ROG.SW) - Market Cap: $250 billion USD, Revenue: $70 billion USD, Employees: 100,000, PE Ratio: 21, Key Products: Pharmaceuticals & Diagnostics\\n\")\n","print(\"• Novartis (NOVN.SW) - Market Cap: $200 billion USD, Revenue: $53 billion USD, Employees: 100,000, PE Ratio: 20, Key Products: Pharmaceuticals & Gene Therapies\\n\")\n","print(\"• Zurich Insurance Group (ZURN.SW) - Market Cap: $70 billion USD, Revenue: $50 billion USD, Employees: 56,000, PE Ratio: 12, Key Products: Insurance & Asset Management\\n\")\n","print(\"• UBS Group (UBSG.SW) - Market Cap: $60 billion USD, Revenue: $35 billion USD, Employees: 72,000, PE Ratio: 9, Key Products: Banking & Wealth Management\\n\")\n","print(\"• ABB Ltd (ABBN.SW) - Market Cap: $60 billion USD, Revenue: $30 billion USD, Employees: 105,000, PE Ratio: 18, Key Products: Robotics & Automation\\n\")\n","print(\"• Cie Financière Richemont (CFR.SW) - Market Cap: $60 billion USD, Revenue: $20 billion USD, Employees: 35,000, PE Ratio: 32, Key Products: Luxury Goods & Jewelry\\n\")\n","print(\"• Alcon (ALC.SW) - Market Cap: $40 billion USD, Revenue: $8 billion USD, Employees: 24,000, PE Ratio: 40, Key Products: Eye Care & Surgical Products\\n\")\n","print(\"• Givaudan (GIVN.SW) - Market Cap: $40 billion USD, Revenue: $7 billion USD, Employees: 16,000, PE Ratio: 35, Key Products: Flavors & Fragrances\\n\")\n","print(\"• Swiss Re (SREN.SW) - Market Cap: $30 billion USD, Revenue: $40 billion USD, Employees: 14,000, PE Ratio: 11, Key Products: Reinsurance\\n\")\n","print(\"• Lonza Group (LONN.SW) - Market Cap: $50 billion USD, Revenue: $6 billion USD, Employees: 17,000, PE Ratio: 25, Key Products: Biotech Solutions & Manufacturing\\n\")\n","print(\"• Swisscom (SCMN.SW) - Market Cap: $30 billion USD, Revenue: $12 billion USD, Employees: 19,000, PE Ratio: 16, Key Products: Telecommunications\\n\")\n","print(\"• Partners Group (PGHN.SW) - Market Cap: $25 billion USD, Revenue: $2 billion USD, Employees: 1,800, PE Ratio: 22, Key Products: Private Equity & Asset Management\\n\")\n","print(\"• Geberit (GEBN.SW) - Market Cap: $20 billion USD, Revenue: $4 billion USD, Employees: 12,000, PE Ratio: 30, Key Products: Sanitary Products\\n\")\n","print(\"• Sika (SIKA.SW) - Market Cap: $40 billion USD, Revenue: $10 billion USD, Employees: 25,000, PE Ratio: 33, Key Products: Construction Chemicals\\n\")\n","print(\"• Julius Baer Group (BAER.SW) - Market Cap: $15 billion USD, Revenue: $4 billion USD, Employees: 6,700, PE Ratio: 13, Key Products: Private Banking\\n\")\n","print(\"• Schindler Holding (SCHN.SW) - Market Cap: $20 billion USD, Revenue: $12 billion USD, Employees: 69,000, PE Ratio: 18, Key Products: Elevators & Escalators\\n\")\n","print(\"• SGS (SGSN.SW) - Market Cap: $20 billion USD, Revenue: $7 billion USD, Employees: 97,000, PE Ratio: 28, Key Products: Inspection & Certification\\n\")\n","print(\"• Logitech International (LOGN.SW) - Market Cap: $10 billion USD, Revenue: $5 billion USD, Employees: 7,000, PE Ratio: 17, Key Products: Computer Accessories\\n\")\n","print(\"• Credit Suisse (CSGN.SW) - Market Cap: $10 billion USD, Revenue: $20 billion USD, Employees: 50,000, PE Ratio: N/A (recent restructuring), Key Products: Banking & Investment\\n\")\n","print(\"• Adecco Group (ADEN.SW) - Market Cap: $8 billion USD, Revenue: $25 billion USD, Employees: 30,000, PE Ratio: 11, Key Products: Staffing & HR Solutions\\n\")\n","print(\"• Lindt & Sprüngli (LISN.SW) - Market Cap: $25 billion USD, Revenue: $5 billion USD, Employees: 14,000, PE Ratio: 45, Key Products: Chocolate & Confectionery\\n\")\n","print(\"• Sonova Holding (SOON.SW) - Market Cap: $20 billion USD, Revenue: $4 billion USD, Employees: 17,000, PE Ratio: 26, Key Products: Hearing Aids\\n\")\n","print(\"• Straumann Holding (STMN.SW) - Market Cap: $20 billion USD, Revenue: $2 billion USD, Employees: 9,000, PE Ratio: 35, Key Products: Dental Implants\\n\")\n","print(\"• Temenos (TEMN.SW) - Market Cap: $8 billion USD, Revenue: $1 billion USD, Employees: 4,000, PE Ratio: 20, Key Products: Banking Software\\n\")\n","print(\"• Helvetia Holding (HELN.SW) - Market Cap: $5 billion USD, Revenue: $10 billion USD, Employees: 11,000, PE Ratio: 8, Key Products: Insurance\\n\")\n","print(\"• Baloise Holding (BALN.SW) - Market Cap: $7 billion USD, Revenue: $9 billion USD, Employees: 7,500, PE Ratio: 9, Key Products: Insurance & Pensions\\n\")\n","print(\"• Clariant (CLN.SW) - Market Cap: $5 billion USD, Revenue: $4 billion USD, Employees: 13,000, PE Ratio: 18, Key Products: Specialty Chemicals\\n\")\n","#print(\"• Kuehne + Nagel (KNIN.SW) - Market Cap: $30 billion USD, Revenue: $30 billion USD, Employees: 79,000, PE Ratio: 15, Key Products: Logistics & Freight\\n\")\n","#print(\"• Dufry (DUFN.SW) - Market Cap: $5 billion USD, Revenue: $7 billion USD, Employees: 20,000, PE Ratio: 12, Key Products: Travel Retail\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YqK8ZBSZo82J","executionInfo":{"status":"ok","timestamp":1730211696889,"user_tz":-60,"elapsed":855,"user":{"displayName":"Vivekanand R","userId":"12007457921190987055"}},"outputId":"1670bb67-ecca-4490-c0ba-8004d2c6b0b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["• Nestlé (NESN.SW) - Market Cap: $340 billion USD, Revenue: $95 billion USD, Employees: 270,000, PE Ratio: 25, Key Products: Food & Beverages\n","\n","• Roche Holding (ROG.SW) - Market Cap: $250 billion USD, Revenue: $70 billion USD, Employees: 100,000, PE Ratio: 21, Key Products: Pharmaceuticals & Diagnostics\n","\n","• Novartis (NOVN.SW) - Market Cap: $200 billion USD, Revenue: $53 billion USD, Employees: 100,000, PE Ratio: 20, Key Products: Pharmaceuticals & Gene Therapies\n","\n","• Zurich Insurance Group (ZURN.SW) - Market Cap: $70 billion USD, Revenue: $50 billion USD, Employees: 56,000, PE Ratio: 12, Key Products: Insurance & Asset Management\n","\n","• UBS Group (UBSG.SW) - Market Cap: $60 billion USD, Revenue: $35 billion USD, Employees: 72,000, PE Ratio: 9, Key Products: Banking & Wealth Management\n","\n","• ABB Ltd (ABBN.SW) - Market Cap: $60 billion USD, Revenue: $30 billion USD, Employees: 105,000, PE Ratio: 18, Key Products: Robotics & Automation\n","\n","• Cie Financière Richemont (CFR.SW) - Market Cap: $60 billion USD, Revenue: $20 billion USD, Employees: 35,000, PE Ratio: 32, Key Products: Luxury Goods & Jewelry\n","\n","• Alcon (ALC.SW) - Market Cap: $40 billion USD, Revenue: $8 billion USD, Employees: 24,000, PE Ratio: 40, Key Products: Eye Care & Surgical Products\n","\n","• Givaudan (GIVN.SW) - Market Cap: $40 billion USD, Revenue: $7 billion USD, Employees: 16,000, PE Ratio: 35, Key Products: Flavors & Fragrances\n","\n","• Swiss Re (SREN.SW) - Market Cap: $30 billion USD, Revenue: $40 billion USD, Employees: 14,000, PE Ratio: 11, Key Products: Reinsurance\n","\n","• Lonza Group (LONN.SW) - Market Cap: $50 billion USD, Revenue: $6 billion USD, Employees: 17,000, PE Ratio: 25, Key Products: Biotech Solutions & Manufacturing\n","\n","• Swisscom (SCMN.SW) - Market Cap: $30 billion USD, Revenue: $12 billion USD, Employees: 19,000, PE Ratio: 16, Key Products: Telecommunications\n","\n","• Partners Group (PGHN.SW) - Market Cap: $25 billion USD, Revenue: $2 billion USD, Employees: 1,800, PE Ratio: 22, Key Products: Private Equity & Asset Management\n","\n","• Geberit (GEBN.SW) - Market Cap: $20 billion USD, Revenue: $4 billion USD, Employees: 12,000, PE Ratio: 30, Key Products: Sanitary Products\n","\n","• Sika (SIKA.SW) - Market Cap: $40 billion USD, Revenue: $10 billion USD, Employees: 25,000, PE Ratio: 33, Key Products: Construction Chemicals\n","\n","• Julius Baer Group (BAER.SW) - Market Cap: $15 billion USD, Revenue: $4 billion USD, Employees: 6,700, PE Ratio: 13, Key Products: Private Banking\n","\n","• Schindler Holding (SCHN.SW) - Market Cap: $20 billion USD, Revenue: $12 billion USD, Employees: 69,000, PE Ratio: 18, Key Products: Elevators & Escalators\n","\n","• SGS (SGSN.SW) - Market Cap: $20 billion USD, Revenue: $7 billion USD, Employees: 97,000, PE Ratio: 28, Key Products: Inspection & Certification\n","\n","• Logitech International (LOGN.SW) - Market Cap: $10 billion USD, Revenue: $5 billion USD, Employees: 7,000, PE Ratio: 17, Key Products: Computer Accessories\n","\n","• Credit Suisse (CSGN.SW) - Market Cap: $10 billion USD, Revenue: $20 billion USD, Employees: 50,000, PE Ratio: N/A (recent restructuring), Key Products: Banking & Investment\n","\n","• Adecco Group (ADEN.SW) - Market Cap: $8 billion USD, Revenue: $25 billion USD, Employees: 30,000, PE Ratio: 11, Key Products: Staffing & HR Solutions\n","\n","• Lindt & Sprüngli (LISN.SW) - Market Cap: $25 billion USD, Revenue: $5 billion USD, Employees: 14,000, PE Ratio: 45, Key Products: Chocolate & Confectionery\n","\n","• Sonova Holding (SOON.SW) - Market Cap: $20 billion USD, Revenue: $4 billion USD, Employees: 17,000, PE Ratio: 26, Key Products: Hearing Aids\n","\n","• Straumann Holding (STMN.SW) - Market Cap: $20 billion USD, Revenue: $2 billion USD, Employees: 9,000, PE Ratio: 35, Key Products: Dental Implants\n","\n","• Temenos (TEMN.SW) - Market Cap: $8 billion USD, Revenue: $1 billion USD, Employees: 4,000, PE Ratio: 20, Key Products: Banking Software\n","\n","• Helvetia Holding (HELN.SW) - Market Cap: $5 billion USD, Revenue: $10 billion USD, Employees: 11,000, PE Ratio: 8, Key Products: Insurance\n","\n","• Baloise Holding (BALN.SW) - Market Cap: $7 billion USD, Revenue: $9 billion USD, Employees: 7,500, PE Ratio: 9, Key Products: Insurance & Pensions\n","\n","• Clariant (CLN.SW) - Market Cap: $5 billion USD, Revenue: $4 billion USD, Employees: 13,000, PE Ratio: 18, Key Products: Specialty Chemicals\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"G9IZTnL-iEQx"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":6577,"status":"error","timestamp":1730212248643,"user":{"displayName":"Vivekanand R","userId":"12007457921190987055"},"user_tz":-60},"id":"wqVW3NP9eqhD","outputId":"d8909d10-ec76-4476-b060-fefed3290748"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Number of tickers: 30\n","Processing 1/30: NESN.SW...\n"]},{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed\n"]},{"output_type":"error","ename":"ValueError","evalue":"Data must be 1-dimensional, got ndarray of shape (252, 1) instead","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-290e12e025c5>\u001b[0m in \u001b[0;36m<cell line: 193>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;31m# Execute the main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-290e12e025c5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing {index + 1}/{len(tickers)}: {ticker}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mresult_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_indicators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mall_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-290e12e025c5>\u001b[0m in \u001b[0;36mcalculate_indicators\u001b[0;34m(ticker)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# Get today's and yesterday's score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mscore_today\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_today\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mscore_yesterday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_yesterday\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-290e12e025c5>\u001b[0m in \u001b[0;36mget_score\u001b[0;34m(data, day_offset)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# MACD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mmacd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMACD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmacd_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mmacd_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmacd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mday_offset\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MACD'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmacd_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ta/trend.py\u001b[0m in \u001b[0;36mmacd_diff\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \"\"\"\n\u001b[1;32m    152\u001b[0m         \u001b[0mmacd_diff_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_macd_diff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         return pd.Series(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0mmacd_diff_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"MACD_diff_{self._window_fast}_{self._window_slow}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.data_manager\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         return sanitize_array(\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    657\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m     \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_ndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36m_sanitize_ndim\u001b[0;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    719\u001b[0m                 \u001b[0;34mf\"Data must be 1-dimensional, got ndarray of shape {data.shape} instead\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (252, 1) instead"]}],"source":["# Import necessary libraries\n","import yfinance as yf\n","import pandas as pd\n","import ta\n","import numpy as np\n","from google.colab import drive\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\", category=FutureWarning, module='ta.trend')\n","\n","# Mount Google Drive to save files\n","drive.mount('/content/drive', force_remount=True)\n","\n","# File paths\n","drive_path = '/content/drive/My Drive/Colab Notebooks'\n","output_file_path = f'{drive_path}/BB_Results_v5A_US1000_12cons_2RSI_Backtesting_v1.xlsx'\n","\n","# Function to calculate indicators for a given ticker\n","def calculate_indicators(ticker):\n","    data = yf.download(ticker, period='1y', interval='1d')\n","    if data.empty or len(data) < 200:  # Ensure there is enough data for long-term indicators\n","        print(f\"Insufficient data for {ticker}\")\n","        return pd.DataFrame()  # Skip this stock\n","\n","    # Calculate scores for today and yesterday\n","    def get_score(data, day_offset=0):\n","        score = 0\n","        results = {}\n","\n","        # MACD\n","        macd = ta.trend.MACD(data['Close']).macd_diff()\n","        macd_score = int(macd.iloc[-1 - day_offset] > 0)\n","        results['MACD'] = macd_score\n","        score += macd_score\n","\n","        # RSI with additional condition (RSI yesterday > RSI day before yesterday)\n","        rsi = ta.momentum.RSIIndicator(data['Close']).rsi()\n","        rsi_score = int(30 < rsi.iloc[-1 - day_offset] < 60 and rsi.iloc[-1 - day_offset] > rsi.iloc[-2 - day_offset])\n","        results['RSI'] = rsi_score\n","        score += rsi_score\n","\n","        # Golden Cross\n","        sma50 = ta.trend.SMAIndicator(data['Close'], 50).sma_indicator()\n","        sma200 = ta.trend.SMAIndicator(data['Close'], 200).sma_indicator()\n","        ma_score = int(sma50.iloc[-1 - day_offset] > sma200.iloc[-1 - day_offset])\n","        results['Golden Cross'] = ma_score\n","        score += ma_score\n","\n","        # Bollinger Bands\n","        bb = ta.volatility.BollingerBands(data['Close'])\n","        middle_band = bb.bollinger_mavg()\n","        bb_score = int(data['Close'].iloc[-1 - day_offset] > middle_band.iloc[-1 - day_offset])\n","        results['Bollinger Bands'] = bb_score\n","        score += bb_score\n","\n","        # Volume\n","        avg_vol = data['Volume'].rolling(window=20).mean()\n","        vol_score = int(data['Volume'].iloc[-1 - day_offset] > avg_vol.iloc[-1 - day_offset])\n","        results['Volume'] = vol_score\n","        score += vol_score\n","\n","        # OBV\n","        obv = ta.volume.OnBalanceVolumeIndicator(data['Close'], data['Volume']).on_balance_volume()\n","        obv_score = int(obv.diff().iloc[-1 - day_offset] > 0)\n","        results['OBV'] = obv_score\n","        score += obv_score\n","\n","        # Accumulation/Distribution Line\n","        ad = ta.volume.AccDistIndexIndicator(data['High'], data['Low'], data['Close'], data['Volume']).acc_dist_index()\n","        ad_score = int(ad.diff().iloc[-1 - day_offset] > 0)\n","        results['Acc/Dist Line'] = ad_score\n","        score += ad_score\n","\n","        # Chaikin Money Flow\n","        cmf = ta.volume.ChaikinMoneyFlowIndicator(data['High'], data['Low'], data['Close'], data['Volume']).chaikin_money_flow()\n","        cmf_score = int(cmf.iloc[-1 - day_offset] > 0)\n","        results['CMF'] = cmf_score\n","        score += cmf_score\n","\n","        # Parabolic SAR\n","        psar = ta.trend.PSARIndicator(data['High'], data['Low'], data['Close']).psar()\n","        psar_score = int(data['Close'].iloc[-1 - day_offset] > psar.iloc[-1 - day_offset])\n","        results['Parabolic SAR'] = psar_score\n","        score += psar_score\n","\n","        # Stochastic Oscillator\n","        stoch = ta.momentum.StochasticOscillator(data['High'], data['Low'], data['Close'])\n","        stoch_score = int(stoch.stoch_signal().iloc[-1 - day_offset] > stoch.stoch().iloc[-1 - day_offset] and stoch.stoch().iloc[-1 - day_offset] < 20)\n","        results['Stochastic'] = stoch_score\n","        score += stoch_score\n","\n","        # Fibonacci Retracement\n","        max_price = data['Close'].max()\n","        min_price = data['Close'].min()\n","        fib_50 = min_price + (max_price - min_price) * 0.5\n","        fib_score = int(data['Close'].iloc[-1 - day_offset] > fib_50)\n","        results['Fib Retracement'] = fib_score\n","        score += fib_score\n","\n","        # ADX\n","        adx = ta.trend.ADXIndicator(data['High'], data['Low'], data['Close']).adx()\n","        plus_di = ta.trend.ADXIndicator(data['High'], data['Low'], data['Close']).adx_pos()\n","        minus_di = ta.trend.ADXIndicator(data['High'], data['Low'], data['Close']).adx_neg()\n","        adx_score = int(adx.iloc[-1 - day_offset] > 20 and plus_di.iloc[-1 - day_offset] > minus_di.iloc[-1 - day_offset])\n","        results['ADX'] = adx_score\n","        score += adx_score\n","\n","        # Price Action & Trendlines\n","        pa_score = int(data['Close'].iloc[-1 - day_offset] > data['Close'].rolling(window=20).max().iloc[-2 - day_offset])\n","        results['Price Action'] = pa_score\n","        score += pa_score\n","\n","        # Candlestick Patterns (Hammer)\n","        def hammer_pattern(data):\n","            open, close, low = data['Open'], data['Close'], data['Low']\n","            return ((close > open) and (open - low) > 2 * (close - open))\n","\n","        hammer_score = int(hammer_pattern(data.iloc[-1 - day_offset]))\n","        results['Candlestick'] = hammer_score\n","        score += hammer_score\n","\n","        # Ichimoku Cloud\n","        ichimoku = ta.trend.IchimokuIndicator(data['High'], data['Low'], window1=9, window2=26, window3=52)\n","        ich_score = int(data['Close'].iloc[-1 - day_offset] > ichimoku.ichimoku_a().iloc[-1 - day_offset] and data['Close'].iloc[-1 - day_offset] > ichimoku.ichimoku_b().iloc[-1 - day_offset])\n","        results['Ichimoku'] = ich_score\n","        score += ich_score\n","\n","        return score, results\n","\n","    # Get today's and yesterday's score\n","    score_today, results_today = get_score(data)\n","    score_yesterday, results_yesterday = get_score(data, day_offset=1)\n","\n","    # Create result DataFrame\n","    result_df = pd.DataFrame([results_today])\n","    result_df['Stock'] = ticker\n","    result_df['Bullish Score Today'] = score_today\n","    result_df['Bullish Score Yesterday'] = score_yesterday\n","    result_df['Score Difference'] = score_today - score_yesterday\n","\n","    # Add Today Change % and Yesterday Change %\n","    result_df['Today Change %'] = (data['Close'].iloc[-1] - data['Close'].iloc[-2]) / data['Close'].iloc[-2] * 100\n","    result_df['Yesterday Change %'] = (data['Close'].iloc[-2] - data['Close'].iloc[-3]) / data['Close'].iloc[-3] * 100\n","\n","    # Reorder columns for better presentation\n","    columns_order = ['Stock'] + list(results_today.keys()) + ['Bullish Score Today', 'Bullish Score Yesterday', 'Score Difference', 'Today Change %', 'Yesterday Change %']\n","    result_df = result_df[columns_order]\n","\n","    return result_df\n","\n","# Main function to process specific tickers\n","def main():\n","    # Hardcoded list of tickers you want to analyze\n","    tickers = [\n","        'NESN.SW', 'ROG.SW', 'NOVN.SW', 'ZURN.SW', 'UBSG.SW', 'ABBN.SW',\n","        'CFR.SW', 'ALC.SW', 'GIVN.SW', 'SREN.SW', 'LONN.SW', 'SCMN.SW',\n","        'PGHN.SW', 'GEBN.SW', 'SIKA.SW', 'BAER.SW', 'SCHN.SW', 'SGSN.SW',\n","        'LOGN.SW', 'CSGN.SW', 'ADEN.SW', 'LISN.SW', 'SOON.SW', 'STMN.SW',\n","        'TEMN.SW', 'HELN.SW', 'BALN.SW', 'CLN.SW', 'KNIN.SW', 'DUFN.SW'\n","    ]\n","    number_of_tickers = len(tickers)\n","    print(\"Number of tickers:\", number_of_tickers)\n","\n","    # Initialize a list to store results for each ticker\n","    all_results = []\n","\n","    # Calculate indicators for each ticker and collect results\n","    for index, ticker in enumerate(tickers):\n","        print(f\"Processing {index + 1}/{len(tickers)}: {ticker}...\")\n","        result_df = calculate_indicators(ticker)\n","        if not result_df.empty:\n","            all_results.append(result_df)\n","\n","    # Combine all results into a single DataFrame\n","    if all_results:\n","        final_df = pd.concat(all_results, ignore_index=True)\n","        final_df = final_df.sort_values(by='Score Difference', ascending=False)\n","        final_df2 = final_df\n","        display(final_df2)\n","\n","        # Save the results to the Excel file\n","        try:\n","            existing_df = pd.read_excel(output_file_path)\n","            final_df = pd.concat([existing_df, final_df], ignore_index=True)\n","        except FileNotFoundError:\n","            print(f\"{output_file_path} not found. A new file will be created.\")\n","\n","        final_df.to_excel(output_file_path, index=False)\n","    else:\n","        print(\"No valid signals detected for any stock.\")\n","\n","# Execute the main function\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oCv9a2iP98Pm"},"outputs":[],"source":["# Note: Financial markets are subject to highly volatile and non-stationary. AI and Data exploration purpose."]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1KT7XTEeROdTQ9hLHKu0nHFeKI019vL6H","timestamp":1730212257765},{"file_id":"1HFiWVjpLrj4xLMHomXtnqWXbkbdUKOD9","timestamp":1728992590158},{"file_id":"1Kol7EhCJyaPb2nsYqMvNvymparG1xImk","timestamp":1727721118231},{"file_id":"1mkv9YoUrjh-KJ-h-PWRCf3xop5sC9gK2","timestamp":1727205715866},{"file_id":"1JKCr9Fng93o42ntH3eMGuOYd1v2owrVp","timestamp":1727205306759},{"file_id":"1TXinRCmEtQbkqMmD4IPFtuG0QGRkdRPx","timestamp":1726601917186},{"file_id":"1B-T6MFBZBCSD2HiGlj22AFkGQdB9zazD","timestamp":1723238136145}],"mount_file_id":"1GBeuY_8TkL8Kwo_YoQmRvK2A3f11T4aM","authorship_tag":"ABX9TyPaeYL2ViFSX1O3R3MEyPg3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}